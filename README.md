# House Price Prediction Project

## ğŸ¯ Project Overview
This project implements a comprehensive machine learning regression pipeline to predict house prices. The goal is to build, compare, and optimize multiple regression models while achieving a significant reduction in RMSE (Root Mean Square Error).

## ğŸ“š Learning Objectives
- Build end-to-end ML regression pipeline using scikit-learn and pandas
- Compare multiple regression algorithms
- Implement proper data preprocessing and feature engineering
- Apply cross-validation and hyperparameter tuning
- Achieve measurable performance improvements (target: 15% RMSE reduction)

## ğŸ› ï¸ Technologies Used
- **Python 3.8+**
- **pandas**: Data manipulation and analysis
- **scikit-learn**: Machine learning algorithms and tools
- **numpy**: Numerical computations
- **matplotlib & seaborn**: Data visualization
- **plotly**: Interactive visualizations
- **xgboost**: Gradient boosting framework

## ğŸ“ Project Structure
```
house-price-prediction/
â”œâ”€â”€ data/                   # Dataset files
â”œâ”€â”€ notebooks/             # Jupyter notebooks for exploration
â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â”œâ”€â”€ model_evaluation.py
â”‚   â””â”€â”€ pipeline.py
â”œâ”€â”€ models/                # Saved model files
â”œâ”€â”€ results/               # Performance metrics and plots
â”œâ”€â”€ requirements.txt       # Project dependencies
â””â”€â”€ README.md             # Project documentation
```

## ğŸš€ Getting Started

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Run the Project
```bash
python src/main.py
```

## ğŸ“Š Expected Outcomes
- Comprehensive EDA with insights about house price factors
- Multiple trained regression models (Linear, Random Forest, Gradient Boosting, XGBoost)
- Model comparison report with performance metrics
- Optimized final model with 15%+ RMSE improvement
- Production-ready prediction pipeline

## ğŸ“ˆ Performance Metrics
- **RMSE** (Root Mean Square Error) - Primary metric
- **MAE** (Mean Absolute Error)
- **RÂ²** (Coefficient of Determination)
- **Cross-validation scores**

## ğŸ“ Key Learning Points
1. **Data Preprocessing**: Handling missing values, feature scaling, encoding
2. **Feature Engineering**: Creating meaningful features from raw data
3. **Model Selection**: Comparing different algorithms systematically
4. **Hyperparameter Tuning**: Optimizing model performance
5. **Pipeline Creation**: Building reusable, production-ready code